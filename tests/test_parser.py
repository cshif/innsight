"""
Comprehensive test suite for parser module covering all requirements.

This test suite validates:
1. API output format consistency
2. Days extraction with Arabic and Chinese numerals
3. Filter extraction for accommodation features
4. Boundary conditions and error scenarios
5. Performance requirements
6. Integration testing
"""

from pytest import raises, fail, main
import time
import random
from typing import List

from scripts.parser import (
    extract_days, extract_filters, extract_poi, parse_query,
    DaysOutOfRangeError, ParseConflictError, ParseError,
    DaysExtractor, FilterExtractor, PoiExtractor, ChineseNumberParser,
    extract_location_from_query
)


class TestChineseNumberParser:
    """Test the Chinese number parser helper class."""
    
    def test_arabic_numbers(self):
        """Test parsing of Arabic numerals."""
        assert ChineseNumberParser.parse("1") == 1
        assert ChineseNumberParser.parse("10") == 10
        assert ChineseNumberParser.parse("99") == 99
    
    def test_chinese_numbers(self):
        """Test parsing of Chinese numerals."""
        assert ChineseNumberParser.parse("ä¸€") == 1
        assert ChineseNumberParser.parse("äºŒ") == 2
        assert ChineseNumberParser.parse("å") == 10
        assert ChineseNumberParser.parse("å…©") == 2
        assert ChineseNumberParser.parse("åŠ") == 0.5
    
    def test_invalid_numbers(self):
        """Test parsing of invalid number strings."""
        assert ChineseNumberParser.parse("abc") == 0
        assert ChineseNumberParser.parse("") == 0
        assert ChineseNumberParser.parse("unknown") == 0


class TestDaysExtractor:
    """Test the days extraction functionality."""
    
    def setup(self):
        """Set up test fixtures."""
        self.extractor = DaysExtractor()
    
    def test_arabic_numerals_with_units(self):
        """Test Arabic numerals with different day units."""
        extractor = DaysExtractor()
        assert extractor.extract("é è¨ˆå¾…2å¤©") == 2
        assert extractor.extract("ä½3æ—¥") == 3
        assert extractor.extract("å¾…4æ™š") == 4
        assert extractor.extract("ä½5å¤œ") == 5
    
    def test_chinese_numerals_with_units(self):
        """Test Chinese numerals with different day units."""
        extractor = DaysExtractor()
        assert extractor.extract("æƒ³ä½å…©å¤©ä¸€å¤œ") == 2
        assert extractor.extract("æ‰“ç®—ä½ä¸‰æ™š") == 3
        assert extractor.extract("ä½ä¸€å¤©") == 1
        assert extractor.extract("å››æ—¥éŠ") == 4
    
    def test_half_day_patterns(self):
        """Test that half day patterns return None."""
        extractor = DaysExtractor()
        assert extractor.extract("åªå»åŠå¤©") is None
        assert extractor.extract("åŠæ—¥éŠ") is None
        assert extractor.extract("æƒ³ä½ä¸€å¤©å…©å¤œ") is None

    def test_comprehensive_number_coverage(self):
        """Test comprehensive coverage of numbers and units."""
        extractor = DaysExtractor()
        
        # Test Arabic numbers 1-14 with all units
        for i in range(1, 15):
            assert extractor.extract(f"ä½{i}å¤©") == i
            assert extractor.extract(f"å¾…{i}æ—¥") == i
            assert extractor.extract(f"ä½{i}æ™š") == i
        
        # Test Chinese numbers with units
        chinese_nums = {
            'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 
            'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
            'åä¸€': 11, 'åäºŒ': 12, 'åä¸‰': 13, 'åå››': 14, 'å…©': 2
        }
        
        for chinese, num in chinese_nums.items():
            assert extractor.extract(f"ä½{chinese}å¤©") == num
            assert extractor.extract(f"å¾…{chinese}æ—¥") == num
            assert extractor.extract(f"ä½{chinese}æ™š") == num
    
    def test_days_out_of_range(self):
        """Test that days > 14 raise DaysOutOfRangeError."""
        extractor = DaysExtractor()
        
        with raises(DaysOutOfRangeError):
            extractor.extract("ä½äºŒåå¤©")
        with raises(DaysOutOfRangeError):
            extractor.extract("ä½15å¤©")
        with raises(DaysOutOfRangeError):
            extractor.extract("ä½100å¤©")
    
    def test_conflicting_days(self):
        """Test that conflicting day specifications raise ParseConflictError."""
        extractor = DaysExtractor()
        
        with raises(ParseConflictError):
            extractor.extract("å…©å¤©ä¸€å¤œä¸‰æ™š")
        with raises(ParseConflictError):
            extractor.extract("ä½2å¤©å¾…5æ™š")
        with raises(ParseConflictError):
            extractor.extract("ä½1å¤©å¾…3æ™š")
    
    def test_acceptable_patterns(self):
        """Test that acceptable patterns like 'å…©å¤©ä¸€å¤œ' work correctly."""
        extractor = DaysExtractor()
        
        # These should work (Nå¤©(N-1)å¤œ patterns)
        assert extractor.extract("å…©å¤©ä¸€å¤œ") == 2
        assert extractor.extract("ä¸‰å¤©äºŒå¤œ") == 3
        assert extractor.extract("å››å¤©ä¸‰æ™š") == 4
    
    def test_edge_cases(self):
        """Test edge cases and invalid inputs."""
        extractor = DaysExtractor()
        
        assert extractor.extract(None) is None
        assert extractor.extract("") is None
        assert extractor.extract("æ²’æœ‰å¤©æ•¸") is None
        assert extractor.extract("éš¨æ©Ÿæ–‡å­—") is None
        assert extractor.extract("123abc") is None


class TestFilterExtractor:
    """Test the filter extraction functionality."""
    
    def test_parking_keywords(self):
        """Test parking-related keyword detection."""
        extractor = FilterExtractor()
        
        parking_keywords = ['åœè»Š', 'å¥½åœè»Š', 'åœè»Šå ´', 'è»Šä½', 'åœè»Šä½']
        for keyword in parking_keywords:
            result = extractor.extract([keyword])
            assert 'parking' in result
    
    def test_wheelchair_keywords(self):
        """Test wheelchair accessibility keyword detection."""
        extractor = FilterExtractor()
        
        wheelchair_keywords = ['ç„¡éšœç¤™', 'è¼ªæ¤…', 'è¡Œå‹•ä¸ä¾¿', 'æ®˜éšœ', 'ç„¡éšœç¤™è¨­æ–½']
        for keyword in wheelchair_keywords:
            result = extractor.extract([keyword])
            assert 'wheelchair' in result
    
    def test_kids_keywords(self):
        """Test kids-friendly keyword detection."""
        extractor = FilterExtractor()
        
        kids_keywords = ['è¦ªå­', 'å…’ç«¥', 'å°å­©', 'å­©å­', 'å°æœ‹å‹', 'è¦ªå­å‹å–„']
        for keyword in kids_keywords:
            result = extractor.extract([keyword])
            assert 'kids' in result
    
    def test_pet_keywords(self):
        """Test pet-friendly keyword detection."""
        extractor = FilterExtractor()
        
        pet_keywords = ['å¯µç‰©', 'ç‹—', 'è²“', 'æ¯›å­©', 'å¯µç‰©å‹å–„', 'å¯æ”œå¸¶å¯µç‰©']
        for keyword in pet_keywords:
            result = extractor.extract([keyword])
            assert 'pet' in result
    
    def test_multiple_filters(self):
        """Test extraction of multiple filter categories."""
        extractor = FilterExtractor()
        
        result = extractor.extract(['è¦', 'å¥½åœè»Š', 'ç„¡éšœç¤™'])
        assert 'parking' in result
        assert 'wheelchair' in result
        assert len(result) == 2
        
        result = extractor.extract(['è¦ªå­', 'å‹å–„', 'å¯µç‰©', 'å¯å…¥ä½'])
        assert 'kids' in result
        assert 'pet' in result
        assert len(result) == 2
    
    def test_no_duplicates(self):
        """Test that results contain no duplicates."""
        extractor = FilterExtractor()
        
        result = extractor.extract(['åœè»Š', 'å¥½åœè»Š', 'åœè»Šå ´'])
        assert len(result) == 1
        assert 'parking' in result
    
    def test_split_keywords(self):
        """Test handling of keywords split across tokens."""
        extractor = FilterExtractor()
        
        # Test when jieba splits "ç„¡éšœç¤™" into ['ç„¡', 'éšœç¤™']
        result = extractor.extract(['è¦', 'ç„¡', 'éšœç¤™', 'è¨­æ–½'])
        assert 'wheelchair' in result
    
    def test_no_matches(self):
        """Test when no filter keywords are found."""
        extractor = FilterExtractor()
        
        result = extractor.extract(['æƒ³', 'ä½é£¯åº—'])
        assert result == []
    
    def test_edge_cases(self):
        """Test edge cases and invalid inputs."""
        extractor = FilterExtractor()
        
        assert extractor.extract(None) == []
        assert extractor.extract([]) == []
        assert extractor.extract([None]) == []
        assert extractor.extract([123]) == []
        assert extractor.extract(['random', 'strings']) == []


class TestPoiExtractor:
    """Test the POI extraction functionality."""
    
    def test_specific_poi_extraction(self):
        """Test extraction of specific POI attraction names."""
        extractor = PoiExtractor()
        
        # Test individual POI attractions
        poi_keywords = ['ç¾ã‚‰æµ·æ°´æ—é¤¨', 'é¦–é‡ŒåŸ', 'è¬åº§æ¯›', 'åœ‹éš›é€š', 'DFS', 'æ–°éƒ½å¿ƒ', 
                       'ç‰çƒæ‘', 'ä»Šæ­¸ä»', 'ä¸­åŸåŸè·¡', 'ç€¨åº•å³¶', 'é‚£éœ¸æ©Ÿå ´']
        
        for keyword in poi_keywords:
            result = extractor.extract([keyword])
            assert keyword in result, f"Expected {keyword} in result, got {result}"
    
    def test_multiple_poi_extraction(self):
        """Test extraction of multiple POI attractions."""
        extractor = PoiExtractor()
        
        # Test multiple POIs in one query
        result = extractor.extract(['ç¾ã‚‰æµ·æ°´æ—é¤¨', 'é¦–é‡ŒåŸ', 'è¬åº§æ¯›'])
        assert 'ç¾ã‚‰æµ·æ°´æ—é¤¨' in result
        assert 'é¦–é‡ŒåŸ' in result
        assert 'è¬åº§æ¯›' in result
        assert len(result) == 3
        
        # Test mixed POIs
        result = extractor.extract(['å»', 'åœ‹éš›é€š', 'å’Œ', 'DFS', 'è³¼ç‰©'])
        assert 'åœ‹éš›é€š' in result
        assert 'DFS' in result
        assert len(result) == 2
    
    def test_no_duplicates(self):
        """Test that results contain no duplicates."""
        extractor = PoiExtractor()
        
        # Test same POI mentioned multiple times
        result = extractor.extract(['ç¾ã‚‰æµ·æ°´æ—é¤¨', 'ç¾ã‚‰æµ·æ°´æ—é¤¨'])
        assert len(result) == 1
        assert 'ç¾ã‚‰æµ·æ°´æ—é¤¨' in result
    
    def test_partial_matches(self):
        """Test that partial matches work correctly."""
        extractor = PoiExtractor()
        
        # Test when jieba might split compound words
        result = extractor.extract(['ç¾ã‚‰æµ·', 'æ°´æ—é¤¨'])
        assert 'ç¾ã‚‰æµ·æ°´æ—é¤¨' in result
        
        # Test when POI name appears in larger context
        result = extractor.extract(['æƒ³å»', 'é¦–é‡ŒåŸ', 'åƒè§€'])
        assert 'é¦–é‡ŒåŸ' in result
    
    def test_no_matches(self):
        """Test when no POI keywords are found."""
        extractor = PoiExtractor()
        
        result = extractor.extract(['éš¨æ©Ÿ', 'æ–‡å­—', 'æ¸¬è©¦'])
        assert result == []
        
        # Test common words that aren't POIs
        result = extractor.extract(['è³¼ç‰©', 'åƒé£¯', 'ä½å®¿'])
        assert result == []
    
    def test_edge_cases(self):
        """Test edge cases and invalid inputs."""
        extractor = PoiExtractor()
        
        assert extractor.extract(None) == []
        assert extractor.extract([]) == []
        assert extractor.extract([None]) == []
        assert extractor.extract([123]) == []
        assert extractor.extract(['random', 'strings']) == []


class TestLocationExtractor:
    """Test the location extraction functionality."""
    
    def test_location_extraction_only_cities(self):
        """Test that only cities/regions are extracted, not attractions."""
        location_tests = [
            ('æ²–ç¹©ä¸‰å¤©å…©å¤œ', 'æ²–ç¹©'),
            ('å°åŒ—è‡ªç”±è¡Œ', 'å°åŒ—'),
            ('æ±äº¬è¿ªå£«å°¼æ¨‚åœ’', 'æ±äº¬'),
            ('å¤§é˜ªç’°çƒå½±åŸ', 'å¤§é˜ª'),
            ('äº¬éƒ½å¤è¹Ÿå·¡ç¦®', 'äº¬éƒ½'),
            ('é‚£éœ¸å¸‚å€ä½å®¿', 'æ²–ç¹©'),  # é‚£éœ¸ maps to æ²–ç¹©
            ('Okinawa travel', 'æ²–ç¹©')
        ]
        
        for query, expected_place in location_tests:
            parsed_query = {'poi': []}
            result = extract_location_from_query(parsed_query, query)
            assert result == expected_place, f"Expected {expected_place}, got {result} for query: {query}"
    
    def test_location_with_attractions(self):
        """Test that location is extracted even when attractions are present."""
        # When both location and attractions are present, should return only location
        query = "æ²–ç¹©ç¾ã‚‰æµ·æ°´æ—é¤¨ä¸€æ—¥éŠ"
        parsed_query = {'poi': ['ç¾ã‚‰æµ·æ°´æ—é¤¨']}
        result = extract_location_from_query(parsed_query, query)
        # Should return location, not attraction
        assert result == 'æ²–ç¹©'
    
    def test_no_location_found(self):
        """Test when no location can be extracted."""
        queries = [
            "ä½ä¸‰å¤©å…©å¤œ",
            "è¦ªå­å‹å–„é£¯åº—",
            "è¦æœ‰åœè»Šå ´",
            "éš¨æ©Ÿæ–‡å­—æ¸¬è©¦",
            "å»é¦–é‡ŒåŸåƒè§€",  # Only attraction, no location
            "è¬åº§æ¯›çœ‹å¤•é™½"   # Only attraction, no location
        ]
        
        for query in queries:
            parsed_query = {'poi': []}
            result = extract_location_from_query(parsed_query, query)
            assert result is None, f"Expected None for query: {query}, got {result}"
    
    def test_edge_cases(self):
        """Test edge cases for location extraction."""
        # Test with None/empty inputs
        assert extract_location_from_query(None, "æ²–ç¹©") == "æ²–ç¹©"  # Still checks original query
        assert extract_location_from_query({}, "æ²–ç¹©") == "æ²–ç¹©"
        assert extract_location_from_query({'poi': []}, "") is None
        
        # Test with malformed parsed_query
        assert extract_location_from_query({'invalid': 'data'}, "å°åŒ—") == "å°åŒ—"


class TestApiOutputFormat:
    """Test API output format consistency."""
    
    def test_extract_days_return_type(self):
        """Test that extract_days returns int or None."""
        result = extract_days("é è¨ˆå¾…2å¤©")
        assert isinstance(result, int) or result is None
        
        result = extract_days("æ²’æœ‰å¤©æ•¸")
        assert result is None
        
        result = extract_days("")
        assert result is None
        
        result = extract_days(None)
        assert result is None
    
    def test_extract_filters_return_type(self):
        """Test that extract_filters returns List[str]."""
        result = extract_filters(['è¦', 'å¥½åœè»Š', 'ç„¡éšœç¤™'])
        assert isinstance(result, list)
        assert all(isinstance(item, str) for item in result)
        
        result = extract_filters([])
        assert isinstance(result, list)
        assert result == []
        
        result = extract_filters(None)
        assert isinstance(result, list)
        assert result == []
    
    def test_extract_poi_return_type(self):
        """Test that extract_poi returns List[str]."""
        result = extract_poi(['ç¾ã‚‰æµ·æ°´æ—é¤¨', 'é¦–é‡ŒåŸ'])
        assert isinstance(result, list)
        assert all(isinstance(item, str) for item in result)
        
        result = extract_poi([])
        assert isinstance(result, list)
        assert result == []
        
        result = extract_poi(None)
        assert isinstance(result, list)
        assert result == []


class TestIntegration:
    """Integration tests for the complete parsing functionality."""
    
    def test_parse_query_with_days_and_filters(self):
        """Test parse_query with both days and filters."""
        result = parse_query("æƒ³ä½å…©å¤©ä¸€å¤œï¼Œè¦å¥½åœè»Šçš„è¦ªå­å‹å–„é£¯åº—å»æ²–ç¹©")
        assert result['days'] == 2
        assert 'parking' in result['filters']
        assert 'kids' in result['filters']
        assert result['place'] == 'æ²–ç¹©'
    
    def test_parse_query_days_only(self):
        """Test parse_query with only days."""
        # This should now fail with ParseError since no place or poi
        with raises(ParseError):
            parse_query("é è¨ˆå¾…3å¤©")
    
    def test_parse_query_filters_only(self):
        """Test parse_query with only filters."""
        # This should now fail with ParseError since no place or poi
        with raises(ParseError):
            parse_query("è¦ç„¡éšœç¤™è¨­æ–½")
    
    def test_parse_query_no_matches(self):
        """Test parse_query with no matches."""
        # This should now fail with ParseError since no place or poi
        with raises(ParseError):
            parse_query("éš¨æ©Ÿæ–‡å­—")
    
    def test_parse_query_return_format(self):
        """Test that parse_query returns correct dictionary format."""
        # Use a query that has place to avoid ParseError
        result = parse_query("æ²–ç¹©ä½2å¤©")
        assert isinstance(result, dict)
        assert 'days' in result
        assert 'filters' in result
        assert 'poi' in result
        assert 'place' in result
        assert isinstance(result['filters'], list)
        assert isinstance(result['poi'], list)
        assert isinstance(result['place'], (str, type(None)))
    
    def test_parse_query_with_poi(self):
        """Test parse_query with POI extraction."""
        result = parse_query("æƒ³å»ç¾ã‚‰æµ·æ°´æ—é¤¨çœ‹æµ·è±š")
        assert result['days'] is None
        assert result['filters'] == []
        assert 'ç¾ã‚‰æµ·æ°´æ—é¤¨' in result['poi']
        assert result['place'] is None
    
    def test_parse_query_comprehensive(self):
        """Test parse_query with days, filters, and POI."""
        result = parse_query("ä½å…©å¤©å»é¦–é‡ŒåŸåƒè§€ï¼Œè¦åœè»Šä½å’Œè¦ªå­è¨­æ–½")
        assert result['days'] == 2
        assert 'parking' in result['filters']
        assert 'kids' in result['filters']
        assert 'é¦–é‡ŒåŸ' in result['poi']
        assert result['place'] is None
    
    def test_parse_query_with_place_extraction(self):
        """Test parse_query with place extraction."""
        # Test location with specific attractions
        result = parse_query("æ²–ç¹©ç¾ã‚‰æµ·æ°´æ—é¤¨ä¸€æ—¥éŠ")
        assert result['days'] == 1
        assert result['place'] == 'æ²–ç¹©'  # Location is æ²–ç¹©
        assert 'ç¾ã‚‰æµ·æ°´æ—é¤¨' in result['poi']  # POI is specific attraction
        
        # Test general locations
        result = parse_query("å°åŒ—ä¸‰å¤©å…©å¤œè¦ªå­æ—…éŠ")
        assert result['days'] == 3
        assert result['place'] == 'å°åŒ—'
        assert 'kids' in result['filters']
        assert result['poi'] == []  # No specific attractions mentioned
        
        # Test no place found - this should now fail with ParseError
        with raises(ParseError):
            parse_query("ä½å…©å¤©è¦åœè»Šå ´")


class TestErrorHandling:
    """Test error handling and boundary conditions."""
    
    def test_safe_error_handling_days(self):
        """Test that extract_days handles unexpected inputs safely."""
        test_cases = [
            None, "", "éšæœºå­—ç¬¦ä¸²", "123abc", "!@#$%^&*()",
            "ğŸ¨ğŸš—ğŸ¯", "a" * 1000
        ]
        
        for test_input in test_cases:
            try:
                result = extract_days(test_input)
                assert result is None or isinstance(result, int)
            except (DaysOutOfRangeError, ParseConflictError):
                pass  # These are expected custom errors
            except Exception as e:
                fail(f"Unexpected exception for input '{test_input}': {e}")
    
    def test_safe_error_handling_filters(self):
        """Test that extract_filters handles unexpected inputs safely."""
        test_cases = [
            None, [], [""], [None], [123], ["random", "strings"]
        ]
        
        for test_input in test_cases:
            try:
                result = extract_filters(test_input)
                assert isinstance(result, list)
            except Exception as e:
                fail(f"Unexpected exception for input '{test_input}': {e}")


class TestParseValidation:
    """Test parse validation logic for place and poi requirements."""
    
    def test_parse_error_no_place_no_poi(self):
        """Test that ParseError is raised when both place and poi are missing."""
        queries_should_fail = [
            "æƒ³ä½å…©å¤©",
            "è¦è¦ªå­å‹å–„çš„é£¯åº—", 
            "éœ€è¦åœè»Šå ´",
            "ä½ä¸‰å¤©è¦ç„¡éšœç¤™è¨­æ–½",
            "è¦ªå­åŒè¡Œï¼Œè¦å¯µç‰©å‹å–„",
            "é è¨ˆå¾…ä¸€é€±",
            "æ‰¾æœ‰è¼ªæ¤…é€šé“çš„ä½å®¿",
            "éš¨æ©Ÿæ–‡å­—"
        ]
        
        for query in queries_should_fail:
            with raises(ParseError) as exc_info:
                parse_query(query)
            assert str(exc_info.value) == "ç„¡æ³•åˆ¤æ–·åœ°åæˆ–ä¸»è¡Œç¨‹"
    
    def test_parse_success_with_place_only(self):
        """Test that parsing succeeds when place is found but no poi."""
        queries_should_succeed = [
            ("æ²–ç¹©ä¸‰å¤©å…©å¤œ", "æ²–ç¹©", []),
            ("å°åŒ—è‡ªç”±è¡Œ", "å°åŒ—", []),
            ("æ±äº¬è¿ªå£«å°¼æ¨‚åœ’", "æ±äº¬", []),
            ("å¤§é˜ªç’°çƒå½±åŸ", "å¤§é˜ª", []),
            ("äº¬éƒ½å¤è¹Ÿå·¡ç¦®", "äº¬éƒ½", []),
            ("é‚£éœ¸å¸‚å€ä½å®¿", "æ²–ç¹©", []),
            ("Okinawa travel", "æ²–ç¹©", [])
        ]
        
        for query, expected_place, expected_poi in queries_should_succeed:
            result = parse_query(query)
            assert result['place'] == expected_place
            assert result['poi'] == expected_poi
    
    def test_parse_success_with_poi_only(self):
        """Test that parsing succeeds when poi is found but no place."""
        queries_should_succeed = [
            ("å»é¦–é‡ŒåŸåƒè§€", None, ["é¦–é‡ŒåŸ"]),
            ("ç¾ã‚‰æµ·æ°´æ—é¤¨çœ‹æµ·è±š", None, ["ç¾ã‚‰æµ·æ°´æ—é¤¨"]),
            ("æƒ³å»è¬åº§æ¯›çœ‹å¤•é™½", None, ["è¬åº§æ¯›"]),
            ("åœ‹éš›é€šè³¼ç‰©", None, ["åœ‹éš›é€š"]),
            ("ä»Šæ­¸ä»åŸéºè·¡", None, ["ä»Šæ­¸ä»"])
        ]
        
        for query, expected_place, expected_poi in queries_should_succeed:
            result = parse_query(query)
            assert result['place'] == expected_place
            assert result['poi'] == expected_poi
    
    def test_parse_success_with_both_place_and_poi(self):
        """Test that parsing succeeds when both place and poi are found."""
        queries_should_succeed = [
            ("æ²–ç¹©ç¾ã‚‰æµ·æ°´æ—é¤¨ä¸€æ—¥éŠ", "æ²–ç¹©", ["ç¾ã‚‰æµ·æ°´æ—é¤¨"]),
            ("å°åŒ—æƒ³å»é¦–é‡ŒåŸ", "å°åŒ—", ["é¦–é‡ŒåŸ"]),
            ("æ±äº¬è¡Œç¨‹åŒ…å«è¬åº§æ¯›", "æ±äº¬", ["è¬åº§æ¯›"])
        ]
        
        for query, expected_place, expected_poi in queries_should_succeed:
            result = parse_query(query)
            assert result['place'] == expected_place
            assert result['poi'] == expected_poi
    
    def test_specific_validation_requirement(self):
        """Test the specific requirement from user: æƒ³ä½å…©å¤© should raise ParseError."""
        with raises(ParseError) as exc_info:
            parse_query("æƒ³ä½å…©å¤©")
        assert str(exc_info.value) == "ç„¡æ³•åˆ¤æ–·åœ°åæˆ–ä¸»è¡Œç¨‹"
    
    def test_complex_queries_with_filters_still_fail_without_place_poi(self):
        """Test that complex queries with filters still fail without place or poi."""
        complex_queries = [
            "æƒ³ä½å…©å¤©ä¸€å¤œï¼Œè¦å¥½åœè»Šçš„è¦ªå­å‹å–„é£¯åº—",
            "é è¨ˆå¾…ä¸‰å¤©ï¼Œè¦ç„¡éšœç¤™æˆ¿é–“ï¼Œå¯ä»¥å¸¶å¯µç‰©å—ï¼Ÿ",
            "å››æ—¥ä¸‰å¤œå®¶æ—æ—…è¡Œï¼Œè»Šå­è¦å¥½åœè»Š",
            "ä½ä¸€æ™šå°±å¥½ï¼Œæœ‰æ²’æœ‰é©åˆè¼ªæ¤…çš„æˆ¿é–“"
        ]
        
        for query in complex_queries:
            with raises(ParseError) as exc_info:
                parse_query(query)
            assert str(exc_info.value) == "ç„¡æ³•åˆ¤æ–·åœ°åæˆ–ä¸»è¡Œç¨‹"


class TestPerformance:
    """Test performance requirements."""
    
    def generate_random_sentences(self, count: int, max_length: int = 100) -> List[str]:
        """Generate random Chinese-like sentences for performance testing."""
        sentences = []
        # Use characters that won't cause conflicts in day extraction
        chinese_chars = "æˆ‘ä½ ä»–å¥¹å®ƒå€‘çš„æ˜¯åœ¨æœ‰é€™å€‹é‚£è£¡è¦å»ä¾†ä½å¥½è»Šç¤™è¦ªå­å¯µç‰©å‹å–„"
        
        for _ in range(count):
            length = random.randint(10, max_length)
            sentence = ''.join(random.choice(chinese_chars) for _ in range(length))
            sentences.append(sentence)
        
        return sentences
    
    def test_performance_10000_sentences(self):
        """Test processing 10,000 sentences in â‰¤1 second."""
        sentences = self.generate_random_sentences(10000, 100)
        
        start_time = time.time()
        
        for sentence in sentences:
            extract_days(sentence)
            tokens = [sentence[i:i+2] for i in range(0, len(sentence), 2)]
            extract_filters(tokens)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        assert processing_time <= 1.0, f"Processing took {processing_time:.3f}s, should be â‰¤1.0s"
        print(f"Performance test passed: {processing_time:.3f}s for 10,000 sentences")


class TestEdgeCases:
    """Test various edge cases and special scenarios."""
    
    def test_mixed_language_input(self):
        """Test with mixed Chinese and English input."""
        result = extract_days("ä½2å¤© stay 3 days")
        assert result == 2
    
    def test_special_characters(self):
        """Test with special characters and punctuation."""
        assert extract_days("ä½2å¤©ï¼ï¼ï¼") == 2
        assert extract_days("ä½ï¼Œ2ï¼Œå¤©") == 2
    
    def test_whitespace_handling(self):
        """Test with various whitespace patterns."""
        assert extract_days("  ä½ 2 å¤©  ") == 2
        assert extract_days("ä½\t2\nå¤©") == 2
    
    def test_partial_keyword_matches(self):
        """Test partial keyword matches in filters."""
        result = extract_filters(['åœè»Šä½', 'å¥½åœè»Šå ´'])
        assert 'parking' in result
        assert len(result) == 1
    
    def test_complex_queries(self):
        """Test complex real-world query patterns."""
        queries = [
            "æˆ‘æƒ³ä½å…©å¤©ä¸€å¤œï¼Œéœ€è¦æœ‰åœè»Šå ´å’Œè¦ªå­è¨­æ–½çš„é£¯åº—å»æ²–ç¹©",
            "é è¨ˆå¾…ä¸‰å¤©å»å°åŒ—ï¼Œè¦ç„¡éšœç¤™æˆ¿é–“ï¼Œå¯ä»¥å¸¶å¯µç‰©å—ï¼Ÿ",
            "å››æ—¥ä¸‰å¤œå®¶æ—æ—…è¡Œå»æ±äº¬ï¼Œè»Šå­è¦å¥½åœè»Š",
            "ä½ä¸€æ™šå°±å¥½å»å¤§é˜ªï¼Œæœ‰æ²’æœ‰é©åˆè¼ªæ¤…çš„æˆ¿é–“"
        ]
        
        for query in queries:
            result = parse_query(query)
            assert isinstance(result, dict)
            assert 'days' in result
            assert 'filters' in result
            print(f"Query: {query[:20]}... -> {result}")


# Backward compatibility tests
class TestBackwardCompatibility:
    """Test that the refactored code maintains backward compatibility."""
    
    def test_public_api_functions(self):
        """Test that all public API functions still work."""
        # Test extract_days
        assert extract_days("ä½2å¤©") == 2
        assert extract_days("åŠå¤©") is None
        
        # Test extract_filters
        assert 'parking' in extract_filters(['åœè»Š'])
        assert extract_filters([]) == []
        
        # Test parse_query
        result = parse_query("ä½2å¤©è¦åœè»Šå»æ²–ç¹©")
        assert result['days'] == 2
        assert 'parking' in result['filters']
        assert result['place'] == 'æ²–ç¹©'
    
    def test_exception_classes(self):
        """Test that custom exception classes are still available."""
        with raises(DaysOutOfRangeError):
            extract_days("ä½20å¤©")
        
        with raises(ParseConflictError):
            extract_days("ä½1å¤©å¾…5æ™š")


class TestParserCaching:
    """Test the new caching and dependency injection functionality."""
    
    def test_lru_cache_functionality(self):
        """Test that the lru_cache creates and reuses the same parser instance."""
        from scripts.parser import _get_default_parser
        
        # Get parser twice
        parser1 = _get_default_parser()
        parser2 = _get_default_parser()
        
        # Should be the same instance due to caching
        assert parser1 is parser2
        
        # Verify cache info
        cache_info = _get_default_parser.cache_info()
        assert cache_info.hits >= 1
        assert cache_info.misses == 1
        assert cache_info.maxsize == 1
    
    def test_public_api_uses_same_parser_instance(self):
        """Test that all public API functions use the same cached parser instance."""
        from scripts.parser import (
            _get_default_parser, parse_query, extract_days, 
            extract_filters, extract_poi, clear_parser_cache
        )
        
        # Clear cache to start fresh
        clear_parser_cache()
        
        # Get the default parser instance
        default_parser = _get_default_parser()
        
        # Mock the parser to track usage
        original_parse = default_parser.parse
        original_days_extract = default_parser.days_extractor.extract
        original_filters_extract = default_parser.filter_extractor.extract
        original_poi_extract = default_parser.poi_extractor.extract
        
        parse_calls = []
        days_calls = []
        filters_calls = []
        poi_calls = []
        
        def mock_parse(text):
            parse_calls.append(text)
            return original_parse(text)
        
        def mock_days_extract(text):
            days_calls.append(text)
            return original_days_extract(text)
        
        def mock_filters_extract(tokens):
            filters_calls.append(tokens)
            return original_filters_extract(tokens)
        
        def mock_poi_extract(tokens):
            poi_calls.append(tokens)
            return original_poi_extract(tokens)
        
        # Replace methods with mocks
        default_parser.parse = mock_parse
        default_parser.days_extractor.extract = mock_days_extract
        default_parser.filter_extractor.extract = mock_filters_extract
        default_parser.poi_extractor.extract = mock_poi_extract
        
        try:
            # Call public API functions (without parser parameter)
            parse_query("ä½å…©å¤©å»æ²–ç¹©")
            extract_days("ä½ä¸‰å¤©")
            extract_filters(["åœè»Š"])
            extract_poi(["ç¾ã‚‰æµ·æ°´æ—é¤¨"])
            
            # Verify all functions used the same parser instance
            assert len(parse_calls) == 1
            # parse_query() internally calls days_extractor.extract(), so we expect 2 calls
            assert len(days_calls) == 2  
            # parse_query() internally calls filter_extractor.extract(), so we expect 2 calls
            assert len(filters_calls) == 2
            # parse_query() internally calls poi_extractor.extract(), so we expect 2 calls
            assert len(poi_calls) == 2
            
            # Verify the calls were made through the same instance
            assert parse_calls[0] == "ä½å…©å¤©å»æ²–ç¹©"
            assert "ä½å…©å¤©å»æ²–ç¹©" in days_calls  # from parse_query()
            assert "ä½ä¸‰å¤©" in days_calls  # from extract_days()
            assert ["åœè»Š"] in filters_calls  # from extract_filters()
            assert ["ç¾ã‚‰æµ·æ°´æ—é¤¨"] in poi_calls  # from extract_poi()
            
            # Most importantly, verify they all used the same parser instance
            # by checking that the mock functions were called on the same object
            same_parser_used = (
                default_parser.parse == mock_parse and
                default_parser.days_extractor.extract == mock_days_extract and
                default_parser.filter_extractor.extract == mock_filters_extract and
                default_parser.poi_extractor.extract == mock_poi_extract
            )
            assert same_parser_used
            
        finally:
            # Restore original methods
            default_parser.parse = original_parse
            default_parser.days_extractor.extract = original_days_extract
            default_parser.filter_extractor.extract = original_filters_extract
            default_parser.poi_extractor.extract = original_poi_extract
    
    def test_cache_clearing(self):
        """Test that clear_parser_cache() creates a new parser instance."""
        from scripts.parser import _get_default_parser, clear_parser_cache
        
        # Get initial parser
        parser1 = _get_default_parser()
        
        # Clear cache
        clear_parser_cache()
        
        # Get new parser
        parser2 = _get_default_parser()
        
        # Should be different instances
        assert parser1 is not parser2
        
        # Cache should be reset
        cache_info = _get_default_parser.cache_info()
        assert cache_info.misses >= 1
    
    def test_dependency_injection(self):
        """Test that functions accept custom parser instances."""
        from scripts.parser import (
            parse_query, extract_days, extract_filters, extract_poi,
            QueryParser, DaysExtractor, FilterExtractor, PoiExtractor
        )
        
        # Create custom parser with modified behavior
        custom_parser = QueryParser()
        
        # Test parse_query with custom parser
        result1 = parse_query("ä½å…©å¤©å»æ²–ç¹©")  # Default parser
        result2 = parse_query("ä½å…©å¤©å»æ²–ç¹©", parser=custom_parser)  # Custom parser
        
        # Both should work and produce same results
        assert result1 == result2
        assert result1['days'] == 2
        assert result1['place'] == 'æ²–ç¹©'
        
        # Test individual functions with custom parser
        days = extract_days("ä½ä¸‰å¤©", parser=custom_parser)
        filters = extract_filters(["åœè»Š", "è¦ªå­"], parser=custom_parser)
        poi = extract_poi(["ç¾ã‚‰æµ·æ°´æ—é¤¨"], parser=custom_parser)
        
        assert days == 3
        assert "parking" in filters
        assert "kids" in filters
        assert "ç¾ã‚‰æµ·æ°´æ—é¤¨" in poi
    
    def test_parser_isolation(self):
        """Test that different parser instances don't interfere with each other."""
        from scripts.parser import QueryParser, DaysExtractor
        
        # Create two independent parsers
        parser1 = QueryParser()
        parser2 = QueryParser()
        
        # Verify they are different instances
        assert parser1 is not parser2
        assert parser1.days_extractor is not parser2.days_extractor
        
        # Both should work independently
        result1 = parser1.parse("ä½å…©å¤©è¦ªå­å»æ²–ç¹©")
        result2 = parser2.parse("ä½ä¸‰å¤©åœè»Šå»å°åŒ—")
        
        assert result1['days'] == 2
        assert result2['days'] == 3
        assert "kids" in result1['filters']
        assert "parking" in result2['filters']
        assert result1['place'] == 'æ²–ç¹©'
        assert result2['place'] == 'å°åŒ—'
    
    def test_mock_compatibility(self):
        """Test that the new structure is compatible with mocking."""
        from unittest.mock import Mock
        from scripts.parser import parse_query, QueryParser
        
        # Create a mock parser
        mock_parser = Mock(spec=QueryParser)
        mock_parser.parse.return_value = {
            'days': 99,
            'filters': ['mock_filter'],
            'poi': ['mock_poi']
        }
        
        # Use mock parser
        result = parse_query("any text", parser=mock_parser)
        
        # Verify mock was called and returned expected result
        mock_parser.parse.assert_called_once_with("any text")
        assert result['days'] == 99
        assert result['filters'] == ['mock_filter']
        assert result['poi'] == ['mock_poi']
    
    def test_cache_thread_safety(self):
        """Test that the cache works correctly in multi-threading scenarios."""
        from scripts.parser import _get_default_parser
        import threading
        import time
        
        parsers = []
        
        def get_parser():
            # Small delay to increase chance of race conditions
            time.sleep(0.001)
            parsers.append(_get_default_parser())
        
        # Create multiple threads
        threads = [threading.Thread(target=get_parser) for _ in range(10)]
        
        # Start all threads
        for thread in threads:
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        # All parsers should be the same instance
        first_parser = parsers[0]
        for parser in parsers[1:]:
            assert parser is first_parser


class TestTestabilityImprovements:
    """Test specific testability improvements."""
    
    def setup_method(self):
        """Setup for each test method."""
        from scripts.parser import clear_parser_cache
        clear_parser_cache()
    
    def test_isolated_test_runs(self):
        """Test that tests can run in isolation without affecting each other."""
        from scripts.parser import parse_query, QueryParser
        
        # Test 1: Use default parser
        result1 = parse_query("ä½ä¸€å¤©å»æ²–ç¹©")
        assert result1['days'] == 1
        assert result1['place'] == 'æ²–ç¹©'
        
        # Test 2: Use custom parser (simulates test isolation)
        custom_parser = QueryParser()
        result2 = parse_query("ä½äºŒå¤©å»å°åŒ—", parser=custom_parser)
        assert result2['days'] == 2
        assert result2['place'] == 'å°åŒ—'
        
        # Test 3: Use default parser again
        result3 = parse_query("ä½ä¸‰å¤©å»æ±äº¬")
        assert result3['days'] == 3
        assert result3['place'] == 'æ±äº¬'
        
        # All tests should work independently
        assert result1['days'] != result2['days']
        assert result2['days'] != result3['days']
    
    def test_cache_reset_between_tests(self):
        """Test that cache can be reset between tests."""
        from scripts.parser import _get_default_parser, clear_parser_cache
        
        # Get parser
        parser1 = _get_default_parser()
        parser1_id = id(parser1)
        
        # Clear cache (simulates test teardown)
        clear_parser_cache()
        
        # Get new parser (simulates new test)
        parser2 = _get_default_parser()
        parser2_id = id(parser2)
        
        # Should be different instances
        assert parser1_id != parser2_id
        assert parser1 is not parser2


if __name__ == "__main__":
    main([__file__, "-v"])